{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HW2 \n",
    "\n",
    "# Getting started to process a text example\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165556"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hemingway Analysis\n",
    "hemingway = open('C:\\\\Users\\\\maria\\\\inourtime.txt')\n",
    "text = hemingway.read()\n",
    "len(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "## CODE IDEAS FOR HMW 2, Exploratory exercise for sentiment analysis\n",
    "# finding adverb and adjective phrases, and computing basic statistics\n",
    "\n",
    "# importing required nltk libraries\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "# loading our corpus (for this example: \"Crime and Punishment,\" by F. Dostoevsky)\n",
    "#f = open('CrimeAndPunishment.txt')\n",
    "#text = f.read()\n",
    "#print(text[:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The whole battery was drunk going along\\nthe\\nroad in the dark.']\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing, as explained in the Labs\n",
    "# Separate the text into sentences first\n",
    "textsplit = nltk.sent_tokenize(text)\n",
    "print(textsplit[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['IN', 'OUR', 'TIME', 'Everybody', 'was', 'drunk', '.'], ['The', 'whole', 'battery', 'was', 'drunk', 'going', 'along', 'the', 'road', 'in', 'the', 'dark', '.']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2750"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "# Apply the word tokenizer to each sentence\n",
    "tokentext = [nltk.word_tokenize(sent) for sent in textsplit]\n",
    "print(tokentext[:2])\n",
    "#the output is a list of strings that contains the sentences\n",
    "type(tokentext)\n",
    "len(tokentext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('IN', 'NNP'), ('OUR', 'NNP'), ('TIME', 'NNP'), ('Everybody', 'NNP'), ('was', 'VBD'), ('drunk', 'VBN'), ('.', '.')], [('The', 'DT'), ('whole', 'JJ'), ('battery', 'NN'), ('was', 'VBD'), ('drunk', 'JJ'), ('going', 'VBG'), ('along', 'IN'), ('the', 'DT'), ('road', 'NN'), ('in', 'IN'), ('the', 'DT'), ('dark', 'NN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "## POS Tagging, to retrieve adjective (JJs) and adverb (RBs) tags\n",
    "\n",
    "# use the Stanford POS tagger to POS tag tokens of each sentence\n",
    "# this is the default tagger in nltk\n",
    "\n",
    "taggedtext = [nltk.pos_tag(tokens) for tokens in tokentext]\n",
    "print(taggedtext[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# Following our NLTK textbook, chapter on Information Extraction--Chunking (https://www.nltk.org/book/ch07.html)\n",
    "\n",
    "# Using CHUNKING to parse sentences \n",
    "# to look for \"adjective phrases\", i.e. phrases (or chunks) that have adverbs and adjectives ('RB'+'JJ')\n",
    "# First step: writing a grammar that defines the POS in the chunk\n",
    "# we name this grammar \"ADJPH\" (\"ADJective PHrase\") using regexes \n",
    "\n",
    "import re\n",
    "grammar_adjph = \"ADJPH: {<RB.?>+<JJ.?>}\"\n",
    "# This regex reads as: \"find groups (\"< >\") of RBs (adverbs) together with groups of JJs (adjectives), with groups defineds as\n",
    "# RBs with any ending (the \".\" is a placeholder or wildcard for the \"R\" and the \"S\" at the end of RBR and RBS, \n",
    "# while \"?\" indicates \"optional character\" so RB can be found alone as well). Same regex operators apply to JJs.\n",
    "\n",
    "# Second step: import the nltk parser to process each sentence\n",
    "chunk_parser_adj = nltk.RegexpParser(grammar_adjph)\n",
    "\n",
    "adjph_tags = []\n",
    "for sent in taggedtext:\n",
    "    if len(sent) > 0:\n",
    "        tree = chunk_parser_adj.parse(sent)\n",
    "        for subtree in tree.subtrees():\n",
    "            if subtree.label() == 'ADJPH':\n",
    "                adjph_tags.append(subtree)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 adjective phrases:  ['so soused ', 'very sick ', 'very big ', 'very bad ', 'not important ', 'not important ', 'very pale ', 'away wet ', 'terribly sorry ', 'very exceptional ', \"'Do many \", 'very many ', \"'Do many \", 'quite sure ', 'not worth ', 'very lazy ', 'very uncomfortable ', 'very serious ', 'so much ', 'awfully surprised ', \"n't striking \", 'about right ', 'not quite dark ', 'afrightfully hot ', 'absolutely perfect ', 'simply priceless ', 'Too heavy ', 'absolutely perfect ', 'very jine ', 'sometimes slept ', 'pretty good ', \"'How much \", \"n't practical \", 'consciously practical ', 'quite proud ', 'thoroughly practical ', 'awfully big ', 'very fine ', 'very wise ', 'probably bad ', \"n't drunk \", \"n't engaged/ \", \"n't engaged/ \", 'really drunk ', 'so absolute ', 'still quite drunk ', 'no longer so tragic ', 'not even very important ', 'quite close ', 'not quite right ', 'too many ', \"n't brother \", 'very hot ', 'not enOtigh ', 'very fiat ', 'too big ', 'not beautiful ', 'back much too late ', 'rather ridiculous ', 'back so late ', 'too many ', 'quite unimportant ', 'not sensational ', 'so many ', 'away only little ', 'not very strong ', \"n't worth \", 'all right ', \"n't true \", 'really ripe ', 'not worth ', 'not worth ', 'most interesting ', 'really good ', \"n't much good \", 'about it/ ', 'only too pleased ', 'just angry ', 'once more ', 'too much ', 'too deep ', 'straight up-hill ', 'quite dark ', \"n't so cordial \", 'here till ', 'too rocky ', 'too much ', \"n't worth \", 'very cold ', 'so hardfor ', 'plenty ofweight ', 'pretty good ', 'so hard ', 'too big ', \"n't really bad \", \"n't so much \", 'pretty worried ', 'so beautiful ', 'so thick ', 'very low ', 'so big ', 'along slow ', 'so damned ', 'awfully good ', 'as good ', 'even big ', 'so excited ', 'so bunched ', 'so white ', 'so awfully dead ', 'so much ', 'then smaller ', 'then smaller ', 'very satisfactory ', 'too heavy ', 'much too heavy ', 'far blue ', 'just ordinary ', 'very hot ', 'far upstream ', 'too fast ', 'very hungry ', 'quite level ', 'much smaller ', 'very tired ', 'quite dark ', 'too hot ', 'still too hot ', 'very sensitive ', 'very hungry ', 'very fine ', 'not so cold ', 'too hot ', 'very serious ', 'most serious ', 'Not heavy ', 'too slow ', 'again next ', 'perfectly quiet ', 'down again unddr ', 'very frightened ', 'very heavy ', 'forward flat ', 'very thin ', 'professionally happy ', 'only tired ', 'too great ', 'too tight ', 'so big ', 'as broad ', 'too much ', 'not too deep ', 'very biggest ', 'almost impossible ', 'so low ', 'together overhead ', 'long grey-white ', 'very glad ', 'very good ', 'butfrightfully difficult ']\n"
     ]
    }
   ],
   "source": [
    "# Visualizing the actual adjective phrase\n",
    "adjective_phrases = []\n",
    "for sent in adjph_tags:\n",
    "    temp = ''\n",
    "    for w, t in sent:\n",
    "        temp += w+ ' '    \n",
    "    adjective_phrases.append(temp)\n",
    "    \n",
    "print('First 10 adjective phrases: ', adjective_phrases[:222])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top adjective phrases by frequency: \n",
      "not worth  3\n",
      "too much  3\n",
      "not important  2\n",
      "'Do many  2\n",
      "very serious  2\n",
      "so much  2\n",
      "absolutely perfect  2\n",
      "pretty good  2\n",
      "very fine  2\n",
      "n't engaged/  2\n",
      "too many  2\n",
      "very hot  2\n",
      "too big  2\n",
      "n't worth  2\n",
      "quite dark  2\n",
      "so big  2\n",
      "then smaller  2\n",
      "very hungry  2\n",
      "too hot  2\n",
      "so soused  1\n",
      "very sick  1\n",
      "very big  1\n",
      "very bad  1\n",
      "very pale  1\n",
      "away wet  1\n",
      "terribly sorry  1\n",
      "very exceptional  1\n",
      "very many  1\n",
      "quite sure  1\n",
      "very lazy  1\n",
      "very uncomfortable  1\n",
      "awfully surprised  1\n",
      "n't striking  1\n",
      "about right  1\n",
      "not quite dark  1\n",
      "afrightfully hot  1\n",
      "simply priceless  1\n",
      "Too heavy  1\n",
      "very jine  1\n",
      "sometimes slept  1\n",
      "'How much  1\n",
      "n't practical  1\n",
      "consciously practical  1\n",
      "quite proud  1\n",
      "thoroughly practical  1\n",
      "awfully big  1\n",
      "very wise  1\n",
      "probably bad  1\n",
      "n't drunk  1\n",
      "really drunk  1\n"
     ]
    }
   ],
   "source": [
    "# Following our NLTK textbook, chapter 1 on Language Processing (https://www.nltk.org/book/ch01.html)\n",
    "\n",
    "## FREQUENCY DISTRIBUTIONS\n",
    "# Top 50 adjective phrases\n",
    "freq_adjph = nltk.FreqDist(adjective_phrases)\n",
    "\n",
    "print('Top adjective phrases by frequency: ')\n",
    "for word, freq in freq_adjph.most_common(50):\n",
    "    print(word, freq)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of adjective phrase sentences:  160\n",
      "[Tree('ADJPH', [('so', 'RB'), ('soused', 'JJ')]), Tree('ADJPH', [('very', 'RB'), ('sick', 'JJ')]), Tree('ADJPH', [('very', 'RB'), ('big', 'JJ')]), Tree('ADJPH', [('very', 'RB'), ('bad', 'JJ')]), Tree('ADJPH', [('not', 'RB'), ('important', 'JJ')]), Tree('ADJPH', [('not', 'RB'), ('important', 'JJ')]), Tree('ADJPH', [('very', 'RB'), ('pale', 'JJ')]), Tree('ADJPH', [('away', 'RB'), ('wet', 'JJ')]), Tree('ADJPH', [('terribly', 'RB'), ('sorry', 'JJ')]), Tree('ADJPH', [('very', 'RB'), ('exceptional', 'JJ')]), Tree('ADJPH', [(\"'Do\", 'RB'), ('many', 'JJ')]), Tree('ADJPH', [('very', 'RB'), ('many', 'JJ')]), Tree('ADJPH', [(\"'Do\", 'RB'), ('many', 'JJ')]), Tree('ADJPH', [('quite', 'RB'), ('sure', 'JJ')]), Tree('ADJPH', [('not', 'RB'), ('worth', 'JJ')]), Tree('ADJPH', [('very', 'RB'), ('lazy', 'JJ')]), Tree('ADJPH', [('very', 'RB'), ('uncomfortable', 'JJ')]), Tree('ADJPH', [('very', 'RB'), ('serious', 'JJ')]), Tree('ADJPH', [('so', 'RB'), ('much', 'JJ')]), Tree('ADJPH', [('awfully', 'RB'), ('surprised', 'JJ')]), Tree('ADJPH', [(\"n't\", 'RB'), ('striking', 'JJ')]), Tree('ADJPH', [('about', 'RB'), ('right', 'JJ')]), Tree('ADJPH', [('not', 'RB'), ('quite', 'RB'), ('dark', 'JJ')]), Tree('ADJPH', [('afrightfully', 'RB'), ('hot', 'JJ')]), Tree('ADJPH', [('absolutely', 'RB'), ('perfect', 'JJ')]), Tree('ADJPH', [('simply', 'RB'), ('priceless', 'JJ')]), Tree('ADJPH', [('Too', 'RB'), ('heavy', 'JJ')]), Tree('ADJPH', [('absolutely', 'RB'), ('perfect', 'JJ')]), Tree('ADJPH', [('very', 'RB'), ('jine', 'JJ')]), Tree('ADJPH', [('sometimes', 'RB'), ('slept', 'JJ')]), Tree('ADJPH', [('pretty', 'RB'), ('good', 'JJ')]), Tree('ADJPH', [(\"'How\", 'RB'), ('much', 'JJ')]), Tree('ADJPH', [(\"n't\", 'RB'), ('practical', 'JJ')]), Tree('ADJPH', [('consciously', 'RB'), ('practical', 'JJ')]), Tree('ADJPH', [('quite', 'RB'), ('proud', 'JJ')]), Tree('ADJPH', [('thoroughly', 'RB'), ('practical', 'JJ')]), Tree('ADJPH', [('awfully', 'RB'), ('big', 'JJ')]), Tree('ADJPH', [('very', 'RB'), ('fine', 'JJ')]), Tree('ADJPH', [('very', 'RB'), ('wise', 'JJ')]), Tree('ADJPH', [('probably', 'RB'), ('bad', 'JJ')]), Tree('ADJPH', [(\"n't\", 'RB'), ('drunk', 'JJ')]), Tree('ADJPH', [(\"n't\", 'RB'), ('engaged/', 'JJ')]), Tree('ADJPH', [(\"n't\", 'RB'), ('engaged/', 'JJ')]), Tree('ADJPH', [('really', 'RB'), ('drunk', 'JJ')]), Tree('ADJPH', [('so', 'RB'), ('absolute', 'JJ')]), Tree('ADJPH', [('still', 'RB'), ('quite', 'RB'), ('drunk', 'JJ')]), Tree('ADJPH', [('no', 'RB'), ('longer', 'RB'), ('so', 'RB'), ('tragic', 'JJ')]), Tree('ADJPH', [('not', 'RB'), ('even', 'RB'), ('very', 'RB'), ('important', 'JJ')]), Tree('ADJPH', [('quite', 'RB'), ('close', 'JJ')]), Tree('ADJPH', [('not', 'RB'), ('quite', 'RB'), ('right', 'JJ')]), Tree('ADJPH', [('too', 'RB'), ('many', 'JJ')]), Tree('ADJPH', [(\"n't\", 'RB'), ('brother', 'JJR')]), Tree('ADJPH', [('very', 'RB'), ('hot', 'JJ')]), Tree('ADJPH', [('not', 'RB'), ('enOtigh', 'JJ')]), Tree('ADJPH', [('very', 'RB'), ('fiat', 'JJ')]), Tree('ADJPH', [('too', 'RB'), ('big', 'JJ')]), Tree('ADJPH', [('not', 'RB'), ('beautiful', 'JJ')]), Tree('ADJPH', [('back', 'RB'), ('much', 'RB'), ('too', 'RB'), ('late', 'JJ')]), Tree('ADJPH', [('rather', 'RB'), ('ridiculous', 'JJ')]), Tree('ADJPH', [('back', 'RB'), ('so', 'RB'), ('late', 'JJ')]), Tree('ADJPH', [('too', 'RB'), ('many', 'JJ')]), Tree('ADJPH', [('quite', 'RB'), ('unimportant', 'JJ')]), Tree('ADJPH', [('not', 'RB'), ('sensational', 'JJ')]), Tree('ADJPH', [('so', 'RB'), ('many', 'JJ')]), Tree('ADJPH', [('away', 'RB'), ('only', 'RB'), ('little', 'JJ')]), Tree('ADJPH', [('not', 'RB'), ('very', 'RB'), ('strong', 'JJ')]), Tree('ADJPH', [(\"n't\", 'RB'), ('worth', 'JJ')]), Tree('ADJPH', [('all', 'RB'), ('right', 'JJ')]), Tree('ADJPH', [(\"n't\", 'RB'), ('true', 'JJ')]), Tree('ADJPH', [('really', 'RB'), ('ripe', 'JJ')]), Tree('ADJPH', [('not', 'RB'), ('worth', 'JJ')]), Tree('ADJPH', [('not', 'RB'), ('worth', 'JJ')]), Tree('ADJPH', [('most', 'RBS'), ('interesting', 'JJ')]), Tree('ADJPH', [('really', 'RB'), ('good', 'JJ')]), Tree('ADJPH', [(\"n't\", 'RB'), ('much', 'RB'), ('good', 'JJ')]), Tree('ADJPH', [('about', 'RB'), ('it/', 'JJ')]), Tree('ADJPH', [('only', 'RB'), ('too', 'RB'), ('pleased', 'JJ')]), Tree('ADJPH', [('just', 'RB'), ('angry', 'JJ')]), Tree('ADJPH', [('once', 'RB'), ('more', 'JJR')]), Tree('ADJPH', [('too', 'RB'), ('much', 'JJ')]), Tree('ADJPH', [('too', 'RB'), ('deep', 'JJ')]), Tree('ADJPH', [('straight', 'RB'), ('up-hill', 'JJ')]), Tree('ADJPH', [('quite', 'RB'), ('dark', 'JJ')]), Tree('ADJPH', [(\"n't\", 'RB'), ('so', 'RB'), ('cordial', 'JJ')]), Tree('ADJPH', [('here', 'RB'), ('till', 'JJ')]), Tree('ADJPH', [('too', 'RB'), ('rocky', 'JJ')]), Tree('ADJPH', [('too', 'RB'), ('much', 'JJ')]), Tree('ADJPH', [(\"n't\", 'RB'), ('worth', 'JJ')]), Tree('ADJPH', [('very', 'RB'), ('cold', 'JJ')]), Tree('ADJPH', [('so', 'RB'), ('hardfor', 'JJ')]), Tree('ADJPH', [('plenty', 'RB'), ('ofweight', 'JJ')]), Tree('ADJPH', [('pretty', 'RB'), ('good', 'JJ')]), Tree('ADJPH', [('so', 'RB'), ('hard', 'JJ')]), Tree('ADJPH', [('too', 'RB'), ('big', 'JJ')]), Tree('ADJPH', [(\"n't\", 'RB'), ('really', 'RB'), ('bad', 'JJ')]), Tree('ADJPH', [(\"n't\", 'RB'), ('so', 'RB'), ('much', 'JJ')]), Tree('ADJPH', [('pretty', 'RB'), ('worried', 'JJ')]), Tree('ADJPH', [('so', 'RB'), ('beautiful', 'JJ')]), Tree('ADJPH', [('so', 'RB'), ('thick', 'JJ')]), Tree('ADJPH', [('very', 'RB'), ('low', 'JJ')]), Tree('ADJPH', [('so', 'RB'), ('big', 'JJ')]), Tree('ADJPH', [('along', 'RB'), ('slow', 'JJ')]), Tree('ADJPH', [('so', 'RB'), ('damned', 'JJ')]), Tree('ADJPH', [('awfully', 'RB'), ('good', 'JJ')]), Tree('ADJPH', [('as', 'RB'), ('good', 'JJ')]), Tree('ADJPH', [('even', 'RB'), ('big', 'JJ')]), Tree('ADJPH', [('so', 'RB'), ('excited', 'JJ')]), Tree('ADJPH', [('so', 'RB'), ('bunched', 'JJ')]), Tree('ADJPH', [('so', 'RB'), ('white', 'JJ')]), Tree('ADJPH', [('so', 'RB'), ('awfully', 'RB'), ('dead', 'JJ')]), Tree('ADJPH', [('so', 'RB'), ('much', 'JJ')]), Tree('ADJPH', [('then', 'RB'), ('smaller', 'JJR')]), Tree('ADJPH', [('then', 'RB'), ('smaller', 'JJR')]), Tree('ADJPH', [('very', 'RB'), ('satisfactory', 'JJ')]), Tree('ADJPH', [('too', 'RB'), ('heavy', 'JJ')]), Tree('ADJPH', [('much', 'RB'), ('too', 'RB'), ('heavy', 'JJ')]), Tree('ADJPH', [('far', 'RB'), ('blue', 'JJ')]), Tree('ADJPH', [('just', 'RB'), ('ordinary', 'JJ')]), Tree('ADJPH', [('very', 'RB'), ('hot', 'JJ')]), Tree('ADJPH', [('far', 'RB'), ('upstream', 'JJ')]), Tree('ADJPH', [('too', 'RB'), ('fast', 'JJ')]), Tree('ADJPH', [('very', 'RB'), ('hungry', 'JJ')]), Tree('ADJPH', [('quite', 'RB'), ('level', 'JJ')]), Tree('ADJPH', [('much', 'RB'), ('smaller', 'JJR')]), Tree('ADJPH', [('very', 'RB'), ('tired', 'JJ')]), Tree('ADJPH', [('quite', 'RB'), ('dark', 'JJ')]), Tree('ADJPH', [('too', 'RB'), ('hot', 'JJ')]), Tree('ADJPH', [('still', 'RB'), ('too', 'RB'), ('hot', 'JJ')]), Tree('ADJPH', [('very', 'RB'), ('sensitive', 'JJ')]), Tree('ADJPH', [('very', 'RB'), ('hungry', 'JJ')]), Tree('ADJPH', [('very', 'RB'), ('fine', 'JJ')]), Tree('ADJPH', [('not', 'RB'), ('so', 'RB'), ('cold', 'JJ')]), Tree('ADJPH', [('too', 'RB'), ('hot', 'JJ')]), Tree('ADJPH', [('very', 'RB'), ('serious', 'JJ')]), Tree('ADJPH', [('most', 'RBS'), ('serious', 'JJ')]), Tree('ADJPH', [('Not', 'RB'), ('heavy', 'JJ')]), Tree('ADJPH', [('too', 'RB'), ('slow', 'JJ')]), Tree('ADJPH', [('again', 'RB'), ('next', 'JJ')]), Tree('ADJPH', [('perfectly', 'RB'), ('quiet', 'JJ')]), Tree('ADJPH', [('down', 'RB'), ('again', 'RB'), ('unddr', 'JJ')]), Tree('ADJPH', [('very', 'RB'), ('frightened', 'JJ')]), Tree('ADJPH', [('very', 'RB'), ('heavy', 'JJ')]), Tree('ADJPH', [('forward', 'RB'), ('flat', 'JJ')]), Tree('ADJPH', [('very', 'RB'), ('thin', 'JJ')]), Tree('ADJPH', [('professionally', 'RB'), ('happy', 'JJ')]), Tree('ADJPH', [('only', 'RB'), ('tired', 'JJ')]), Tree('ADJPH', [('too', 'RB'), ('great', 'JJ')]), Tree('ADJPH', [('too', 'RB'), ('tight', 'JJ')]), Tree('ADJPH', [('so', 'RB'), ('big', 'JJ')]), Tree('ADJPH', [('as', 'RB'), ('broad', 'JJ')]), Tree('ADJPH', [('too', 'RB'), ('much', 'JJ')]), Tree('ADJPH', [('not', 'RB'), ('too', 'RB'), ('deep', 'JJ')]), Tree('ADJPH', [('very', 'RB'), ('biggest', 'JJS')]), Tree('ADJPH', [('almost', 'RB'), ('impossible', 'JJ')]), Tree('ADJPH', [('so', 'RB'), ('low', 'JJ')]), Tree('ADJPH', [('together', 'RB'), ('overhead', 'JJ')]), Tree('ADJPH', [('long', 'RB'), ('grey-white', 'JJ')]), Tree('ADJPH', [('very', 'RB'), ('glad', 'JJ')]), Tree('ADJPH', [('very', 'RB'), ('good', 'JJ')]), Tree('ADJPH', [('butfrightfully', 'RB'), ('difficult', 'JJ')])]\n"
     ]
    }
   ],
   "source": [
    "#print the list of our sentences:\n",
    "print('Length of adjective phrase sentences: ', len(adjph_tags))\n",
    "print(adjph_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# Now we look for \"adverb phrases\" or chunks that have 2 consecutive adverbs ('RB')\n",
    "# First step: writing a grammar that defines POS rules of the adverb phrase the chunk\n",
    "# we name this grammar \"ADVPH\" (\"ADVerb PHrase\")\n",
    "grammar_advph = \"ADVPH: {<RB>+<RB>}\"\n",
    "\n",
    "# Second step: import the nltk parser to process each sentence\n",
    "chunk_parser_adv = nltk.RegexpParser(grammar_advph)\n",
    "\n",
    "advph_tags = []\n",
    "for sent in taggedtext:\n",
    "    if len(sent) > 0:\n",
    "        tree = chunk_parser_adv.parse(sent)\n",
    "        for subtree in tree.subtrees():\n",
    "            if subtree.label() == 'ADVPH':\n",
    "                advph_tags.append(subtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 adverb phrases:  ['very hard ', 'farther ahead ', 'very badly ', 'Just then ', 'very carefully ', 'rather not ', 'away so ', 'pretty quietly ', \"'Hardly ever \", 'yellow almost ']\n"
     ]
    }
   ],
   "source": [
    "# Visualizing the actual adjective phrase\n",
    "adverb_phrases = []\n",
    "for sent in advph_tags:\n",
    "    temp = ''\n",
    "    for w, t in sent:\n",
    "        temp += w+ ' '    \n",
    "    adverb_phrases.append(temp)\n",
    "    \n",
    "print('First 10 adverb phrases: ', adverb_phrases[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top adverb phrases by frequency: \n",
      "'All right  10\n",
      "n't ever  6\n",
      "n't really  3\n",
      "down beside  3\n",
      "as well  2\n",
      "not quite  2\n",
      "as far  2\n",
      "here now  2\n",
      "n't much  2\n",
      "n't so  2\n",
      "up again  2\n",
      "As soon  2\n",
      "back there  2\n",
      "far down  2\n",
      "very hard  1\n",
      "farther ahead  1\n",
      "very badly  1\n",
      "Just then  1\n",
      "very carefully  1\n",
      "rather not  1\n",
      "away so  1\n",
      "pretty quietly  1\n",
      "'Hardly ever  1\n",
      "yellow almost  1\n",
      "once again  1\n",
      "far behind  1\n",
      "too late  1\n",
      "'As long  1\n",
      "so far away  1\n",
      "n't drunk  1\n",
      "n't there  1\n",
      "n't even  1\n",
      "'So long  1\n",
      "sore as  1\n",
      "'Were n't  1\n",
      "still quite  1\n",
      "Outside now  1\n",
      "no longer so  1\n",
      "not even very  1\n",
      "very quietly  1\n",
      "back again  1\n",
      "ahead brilliantly  1\n",
      "carefully away  1\n",
      "probably not  1\n",
      "absolutely unexpectedly  1\n",
      "back much too  1\n",
      "back so  1\n",
      "so long back  1\n",
      "away only  1\n",
      "not very  1\n"
     ]
    }
   ],
   "source": [
    "# top 50 adjective phrases\n",
    "freq_advph = nltk.FreqDist(adverb_phrases)\n",
    "\n",
    "print('Top adverb phrases by frequency: ')\n",
    "for word, freq in freq_advph.most_common(50):\n",
    "    print(word, freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of adverb phrase sentences:  141\n"
     ]
    }
   ],
   "source": [
    "#print the list of our sentences:\n",
    "print('Length of adverb phrase sentences: ', len(advph_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top adjective tokens by frequency: \n",
      "old 90\n",
      "big 75\n",
      "good 59\n",
      "other 44\n",
      "little 42\n",
      "current 37\n",
      "long 28\n",
      "hot 27\n",
      "black 22\n",
      "more 21\n",
      "right 21\n",
      "heavy 20\n",
      "first 18\n",
      "deep 17\n",
      "white 16\n",
      "high 16\n",
      "open 15\n",
      "much 14\n",
      "great 14\n",
      "young 12\n",
      "Indian 12\n",
      "hard 12\n",
      "many 12\n",
      "full 11\n",
      "same 11\n",
      "left 10\n",
      "solid 10\n",
      "happy 10\n",
      "dark 10\n",
      "dead 10\n",
      "next 10\n",
      "sick 9\n",
      "bad 9\n",
      "German 9\n",
      "better 9\n",
      "clear 9\n",
      "funny 9\n",
      "last 9\n",
      "smaller 9\n",
      "quiet 8\n",
      "easy 8\n",
      "fat 8\n",
      "yellow 8\n",
      "sweet 8\n",
      "crazy 8\n",
      "fine 8\n",
      "smooth 8\n",
      "fast 8\n",
      "net 8\n",
      "whole 7\n",
      "1745\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "# Top 50 adjective tokens\n",
    "\n",
    "adjective_tokens = []\n",
    "for sentence in taggedtext:\n",
    "    for word, pos in sentence:\n",
    "        if pos in ['JJ', 'JJR', 'JJS']: # adjective, comparative, superlative\n",
    "            if len(word)>1:\n",
    "                adjective_tokens.append(word)\n",
    "freq_adjective = nltk.FreqDist(adjective_tokens)\n",
    "\n",
    "print('Top adjective tokens by frequency: ')\n",
    "for word, freq in freq_adjective.most_common(50):\n",
    "    print(word,freq)\n",
    "    \n",
    "print(len(adjective_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top adverb tokens by frequency: \n",
      "n't 209\n",
      "not 138\n",
      "back 90\n",
      "then 83\n",
      "down 60\n",
      "up 54\n",
      "just 50\n",
      "too 43\n",
      "very 41\n",
      "Then 41\n",
      "away 40\n",
      "so 38\n",
      "again 36\n",
      "always 34\n",
      "never 34\n",
      "right 33\n",
      "there 33\n",
      "now 32\n",
      "ever 31\n",
      "only 25\n",
      "really 23\n",
      "here 17\n",
      "once 17\n",
      "ahead 16\n",
      "far 16\n",
      "along 15\n",
      "around 15\n",
      "Now 15\n",
      "still 14\n",
      "together 14\n",
      "quite 11\n",
      "more 11\n",
      "'All 10\n",
      "out 10\n",
      "forward 10\n",
      "hard 9\n",
      "carefully 9\n",
      "first 9\n",
      "as 9\n",
      "well 9\n",
      "about 9\n",
      "over 9\n",
      "maybe 9\n",
      "slowly 8\n",
      "sometimes 7\n",
      "almost 7\n",
      "even 7\n",
      "long 7\n",
      "much 7\n",
      "later 6\n",
      "1895\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "# Top 50 adverb tokens\n",
    "\n",
    "adverb_tokens = []\n",
    "for sentence in taggedtext:\n",
    "    for word, pos in sentence:\n",
    "        if pos in ['RB', 'RBR', 'RBS']: # adverb, comparative, superlative\n",
    "            if len(word)>1:\n",
    "                adverb_tokens.append(word)\n",
    "freq_adverb = nltk.FreqDist(adverb_tokens)\n",
    "\n",
    "print('Top adverb tokens by frequency: ')\n",
    "for word, freq in freq_adverb.most_common(50):\n",
    "    print(word,freq)\n",
    "\n",
    "print(len(adverb_tokens))\n",
    "#%%\n",
    "\n",
    "## TO DO / YOUR TURN NOW!\n",
    "## NOUN EXTRACTION\n",
    "## VERB EXTRACTION\n",
    "## REMEMBER TO CHECK THE PENN POS TAGS LIST: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "## TO FIND ALL TAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343\n",
      "['so ', 'so soused ', 'very ', 'very sick ', 'very ', 'very big ', 'very ', 'very bad ', 'not ', 'not important ', 'not ', 'not important ', 'very ', 'very pale ', 'away ', 'away wet ', 'terribly ', 'terribly sorry ', 'very ', 'very exceptional ', \"'Do \", \"'Do many \", 'very ', 'very many ', \"'Do \", \"'Do many \", 'quite ', 'quite sure ', 'not ', 'not worth ', 'very ', 'very lazy ', 'very ', 'very uncomfortable ', 'very ', 'very serious ', 'so ', 'so much ', 'awfully ', 'awfully surprised ', \"n't \", \"n't striking \", 'about ', 'about right ', 'not ', 'not quite ', 'not quite dark ', 'afrightfully ', 'afrightfully hot ', 'absolutely ', 'absolutely perfect ', 'simply ', 'simply priceless ', 'Too ', 'Too heavy ', 'absolutely ', 'absolutely perfect ', 'very ', 'very jine ', 'sometimes ', 'sometimes slept ', 'pretty ', 'pretty good ', \"'How \", \"'How much \", \"n't \", \"n't practical \", 'consciously ', 'consciously practical ', 'quite ', 'quite proud ', 'thoroughly ', 'thoroughly practical ', 'awfully ', 'awfully big ', 'very ', 'very fine ', 'very ', 'very wise ', 'probably ', 'probably bad ', \"n't \", \"n't drunk \", \"n't \", \"n't engaged/ \", \"n't \", \"n't engaged/ \", 'really ', 'really drunk ', 'so ', 'so absolute ', 'still ', 'still quite ', 'still quite drunk ', 'no ', 'no longer ', 'no longer so ', 'no longer so tragic ', 'not ', 'not even ', 'not even very ', 'not even very important ', 'quite ', 'quite close ', 'not ', 'not quite ', 'not quite right ', 'too ', 'too many ', \"n't \", \"n't brother \", 'very ', 'very hot ', 'not ', 'not enOtigh ', 'very ', 'very fiat ', 'too ', 'too big ', 'not ', 'not beautiful ', 'back ', 'back much ', 'back much too ', 'back much too late ', 'rather ', 'rather ridiculous ', 'back ', 'back so ', 'back so late ', 'too ', 'too many ', 'quite ', 'quite unimportant ', 'not ', 'not sensational ', 'so ', 'so many ', 'away ', 'away only ', 'away only little ', 'not ', 'not very ', 'not very strong ', \"n't \", \"n't worth \", 'all ', 'all right ', \"n't \", \"n't true \", 'really ', 'really ripe ', 'not ', 'not worth ', 'not ', 'not worth ', 'most ', 'most interesting ', 'really ', 'really good ', \"n't \", \"n't much \", \"n't much good \", 'about ', 'about it/ ', 'only ', 'only too ', 'only too pleased ', 'just ', 'just angry ', 'once ', 'once more ', 'too ', 'too much ', 'too ', 'too deep ', 'straight ', 'straight up-hill ', 'quite ', 'quite dark ', \"n't \", \"n't so \", \"n't so cordial \", 'here ', 'here till ', 'too ', 'too rocky ', 'too ', 'too much ', \"n't \", \"n't worth \", 'very ', 'very cold ', 'so ', 'so hardfor ', 'plenty ', 'plenty ofweight ', 'pretty ', 'pretty good ', 'so ', 'so hard ', 'too ', 'too big ', \"n't \", \"n't really \", \"n't really bad \", \"n't \", \"n't so \", \"n't so much \", 'pretty ', 'pretty worried ', 'so ', 'so beautiful ', 'so ', 'so thick ', 'very ', 'very low ', 'so ', 'so big ', 'along ', 'along slow ', 'so ', 'so damned ', 'awfully ', 'awfully good ', 'as ', 'as good ', 'even ', 'even big ', 'so ', 'so excited ', 'so ', 'so bunched ', 'so ', 'so white ', 'so ', 'so awfully ', 'so awfully dead ', 'so ', 'so much ', 'then ', 'then smaller ', 'then ', 'then smaller ', 'very ', 'very satisfactory ', 'too ', 'too heavy ', 'much ', 'much too ', 'much too heavy ', 'far ', 'far blue ', 'just ', 'just ordinary ', 'very ', 'very hot ', 'far ', 'far upstream ', 'too ', 'too fast ', 'very ', 'very hungry ', 'quite ', 'quite level ', 'much ', 'much smaller ', 'very ', 'very tired ', 'quite ', 'quite dark ', 'too ', 'too hot ', 'still ', 'still too ', 'still too hot ', 'very ', 'very sensitive ', 'very ', 'very hungry ', 'very ', 'very fine ', 'not ', 'not so ', 'not so cold ', 'too ', 'too hot ', 'very ', 'very serious ', 'most ', 'most serious ', 'Not ', 'Not heavy ', 'too ', 'too slow ', 'again ', 'again next ', 'perfectly ', 'perfectly quiet ', 'down ', 'down again ', 'down again unddr ', 'very ', 'very frightened ', 'very ', 'very heavy ', 'forward ', 'forward flat ', 'very ', 'very thin ', 'professionally ', 'professionally happy ', 'only ', 'only tired ', 'too ', 'too great ', 'too ', 'too tight ', 'so ', 'so big ', 'as ', 'as broad ', 'too ', 'too much ', 'not ', 'not too ', 'not too deep ', 'very ', 'very biggest ', 'almost ', 'almost impossible ', 'so ', 'so low ', 'together ', 'together overhead ', 'long ', 'long grey-white ', 'very ', 'very glad ', 'very ', 'very good ', 'butfrightfully ', 'butfrightfully difficult ']\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "# Now we have two lists of POS tags combinations we can compare\n",
    "# We need to get the sentences back from the tagging exercise and run some stats\n",
    "\n",
    "# Create a list of original sentences from the ADJECTIVE phrase subset:\n",
    "adjph_whole_sentences = []\n",
    "\n",
    "# loop over the sentences in the adjective phrase sentences we created:\n",
    "for sents in adjph_tags:\n",
    "    temp=''\n",
    "    for (word,tag) in sents:\n",
    "        temp += word+' '\n",
    "        adjph_whole_sentences.append(temp)\n",
    "        \n",
    "print(len(adjph_whole_sentences))\n",
    "print(adjph_whole_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "# Create a list of original sentences from the ADVERB phrase subset:\n",
    "advph_whole_sentences = []\n",
    "\n",
    "# loop over the sentences in the adjective phrase sentences we created:\n",
    "for sents in advph_tags:\n",
    "    temp=''\n",
    "    for (word,tag) in sents:\n",
    "        temp += word+' '\n",
    "        advph_whole_sentences.append(temp)\n",
    "        \n",
    "print(len(advph_whole_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "# OPTIONAL STEP: Combine lists together to have a single list of adjective/adverb phrases:\n",
    "# Useful to know which sentences are heavy in qualifiers\n",
    "\n",
    "# create a new variable to store all adjective phrase sentences\n",
    "adv_adj_phrase_sentences = adjph_whole_sentences\n",
    "\n",
    "# iterate over adverb phrase sentences\n",
    "for sent in advph_whole_sentences:\n",
    "    # if a sentence is not in the adjective phrases list imported\n",
    "    if sent not in adv_adj_phrase_sentences:\n",
    "        # attach that sentence\n",
    "        adv_adj_phrase_sentences.append(sent)\n",
    "\n",
    "# print the lenght of the list (i.e. number of sentences with both adjective and adverb phrases)\n",
    "print(len(adv_adj_phrase_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.20254545454546\n",
      "162807\n",
      "2750\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "# Following our NLTK textbook, Writing Structural Programs chapter\n",
    "# section on Procedural vs Declarative style (http://www.nltk.org/book_1ed/ch04.html) \n",
    "\n",
    "## CORPUS STATISTICS--SENTENCES LENGTH\n",
    "\n",
    "# Calculating the average length of sentences in the entire corpus\n",
    "# from http://www.nltk.org/book_1ed/ch04.html\n",
    "total_corpus = sum(len(sent) for sent in textsplit) # remember: 'textsplit' is our text split into sentences\n",
    "print(total_corpus / len(textsplit))\n",
    "print(total_corpus)\n",
    "print(len(textsplit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.159235668789808\n",
      "4314\n",
      "471\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "# Calculate the average length of an adjective phrase sentence\n",
    "# We can then compare the average length of the adjective phrases to \n",
    "# the average sentences we calculated for all sentences in the corpus\n",
    "total_adjph_sentences = sum(len(sent) for sent in adjph_whole_sentences) # adjph_whole_sentences stores our adjective phrases\n",
    "print(total_adjph_sentences / len(adjph_whole_sentences))\n",
    "\n",
    "print(total_adjph_sentences)\n",
    "print(len(adjph_whole_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.920962199312715\n",
      "2305\n",
      "291\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average length of an adjective phrase sentence\n",
    "# We can then compare the average length of the adjective phrases to \n",
    "# the average sentences we calculated for all sentences in the corpus\n",
    "total_advph_sentences = sum(len(sent) for sent in advph_whole_sentences) # adjph_whole_sentences stores our adjective phrases\n",
    "print(total_advph_sentences / len(advph_whole_sentences))\n",
    "\n",
    "#%%\n",
    "print(total_advph_sentences)\n",
    "print(len(advph_whole_sentences))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
